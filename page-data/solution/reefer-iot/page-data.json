{"componentChunkName":"component---src-pages-solution-reefer-iot-index-mdx","path":"/solution/reefer-iot/","result":{"pageContext":{"frontmatter":{"title":"The Reefer Simulator as web app","description":"Simple Refrigerator container internet of thing simulator to control temperature, co2, o2 or power sensors to help build dataset or run time monitoring solution."},"relativePagePath":"/solution/reefer-iot/index.mdx","titleType":"append","MdxNode":{"id":"c8a61b4b-4c09-59b5-89a4-36918b72082c","children":[],"parent":"15c0ab85-64ff-50cf-9dab-6880fb4812be","internal":{"content":"---\ntitle: The Reefer Simulator as web app\ndescription: Simple Refrigerator container internet of thing simulator to control temperature, co2, o2 or power sensors to help build dataset or run time monitoring solution.\n---\n\n\n<PageDescription>\nThis Simulator web application is a simple python (3.7) Flask app exposing a REST POST end point to control the type of simulation we want to run and to produce refrigerator container telemetry events to kafka `telemetries` topic.\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Build</AnchorLink>\n  <AnchorLink>Run</AnchorLink>\n  <AnchorLink>Usage Details</AnchorLink>\n</AnchorLinks>\n\n## Overview\n\n\n### Application requirements\n\nThe simulator is not in the critical path for production like component. It is here to help us develop the other components of the solution as we do not have real life Refrigerator container. Here are the simple user stories for this app:\n\n1. when I want to generate mockup telemetries data for my data scientist friend, I want to start the simulator tool from command line so I can get a csv file with telemetry data\n1. when I want to generate mockup telemetries data for my data scientist friend, I want to be able to simulate co2 sensor, o2 sensor, temperature and power sensor issue so I can get relevant data for the machine learning model to make sense\n1. when I want to generate mockup telemetries data for my data scientist friend, I want to start the simulator tool from command line using parameter so I can get save data to a remote document oriented database: mongodb on IBM cloud.\n1. when I want to demonstrate the solution, I want to call a REST api to control the generation of faulty sensor data so I can get the scoring service returning maintenance needed.\n1. when I want to demonstrate the cold chain violation, I want to call a REST api to control a change to the temperature over a time period so cold chain violation can be identified with a complex event processing or AI model.\n\n ![1](./images/reefer-simul-1.png)\n\nThe simulator needs to integrate with kafka / IBM Event Streams deployed as service on the cloud or deployed on OpenShift cluster using Cloud Pak for Integration.\n\n### Design approach\n\nTo support remote control of the simulator while running as webapp, we define a POST operation on the `/control` URL:\n\n![1](images/simulapp-control-swagger.png)\n\n The Json control object defines the number records to produce, the sensor to impact (co2sensor, temperature, o2sensor, power) , the container ID, (one of C01, C02, C03, C04) which carries the product referenced by product_id (one of P01, P02, P03, P04, P05) - The P01 is the covid-19 vaccine:\n\n```json\n    { 'containerID': 'C02',\n    'simulation': 'temperature',\n    'nb_of_records': 4000,\n    \"product_id\":  \"P01\"\n    }\n```\n\nWe have tried to support a domain driven design approach to structure the code, with domain, infrastructure and app modules. The domain module has a unique class for the simulator which main goal is to generate data tuples or records for the different simulation types. It is reused by the standalone simulation CLI tool to generate data at rest, if needed.\n\nAs the simulator is also a webapp we need to package it with [Flask](https://www.fullstackpython.com/flask.html) and run it using one of the Web Server Gateway Interface (WSGI) implementation, like [Gunicorn](http://docs.gunicorn.org/).\n\nIf you want to go over the code, ee recommend to follow [Flask tutorial](https://flask.palletsprojects.com/en/1.1.x/tutorial/).\n\nFlask is a simple library to implement REST based microservice and web application in Python. It has other related projects to add interesting features to develop production ready application. The standard development includes defining routes, function to support handling the request and generating HTTP response, but also defining APIs... Read more with the [explore Flask book online](http://exploreflask.com/en/latest/).\n\nFlask is mono threaded so it fits well in a simple web application for development purpose, but for production it is recommended to add a web server like [Gunicorn](https://gunicorn.org/) to handle multiple concurrent requests.\n\n### Anatomy\n\nThe application is built using [Appsody](https://appsody.dev). The [Appsody CLI](https://appsody.dev/docs/getting-started/installation) is required locally to build and deploy the application properly.\n\nThe app is done using Flask, and the code is generated using `appsody init python-flask` command with the Python Flask appsody stack and template.\n\nWe recommend reading [the Python Flask Appsody Stack git hub repo](https://github.com/appsody/stacks/tree/master/incubator/python-flask) to get familiar with the appsody python stack.\n\nThe Flask application imports the 'userapp' where the real application code resides, and adds blueprints to define health and metrics APIs:\n\n```python\nfrom flask import Flask\n\napp = Flask(__name__)\n\nfrom userapp import *\n\nfrom server.routes.health import health_bp\napp.register_blueprint(health_bp)\nfrom server.routes.prometheus import metrics_bp\napp.register_blueprint(metrics_bp)\n```\n\nThis code is not updateable, as it is part of the appsody stack image. But we can add our business logic as part of the `domain/__init__.py` code using another [Flask blueprints](https://flask.palletsprojects.com/en/1.1.x/blueprints/) module [api/controller.py]().\n\nThe `userapp` module is defined when appsody integrates our code with the base stack image using Docker. Below is an extract of the docker file managing module installation and defining what appsody does during build, run and test:\n\n```dockerfile\nENV APPSODY_MOUNTS=/:/project/userapp\nENV APPSODY_DEPS=/project/deps\nWORKDIR /project\nRUN python -m pip install -r requirements.txt -t /project/deps\nENV FLASK_APP=server/__init__.py\n```\n\nLooking at the content of the final docker container running the application we can see this structure:\n\n```\n/project\n|-- Dockerfile\n    Pipfile\n    Pipfile.lock\n    constraints.txt\n    requirements.txt\n    deps/\n    server/\n    test/\n    userapp/\n```\n\nThe basic concept of blueprints is that they record operations to execute when each operation is registered on an application. So to add one operation to support a new control, we add a blueprint, and then register it in the main application: `__init__py`.\n\n```python\nfrom userapp.api.controller import control_blueprint\napp.register_blueprint(control_blueprint)\n```\n\nTo define the API, we use [Flasgger](https://github.com/flasgger/flasgger) as an extension to Flask to extract [Open API specification](https://swagger.io/docs/specification/about/) from the code. It comes with Swagger UI, so we can see the API documentation of the microservice at the URL `/apidocs`.  It can also validate the data according to the schema defined.\n\nFor the POST `/control` we defined the Swagger 2.0 API in a separate file: `api/controlapi.yml` and import it at the method level to support the POST operation. This method is defined in its blueprint as a REST resource. The code [controller.py](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator/blob/master/simulator/api/controller.py) is under `api` folder.\n\nBelow is a code extract to illustrate the use of Flask-RESTful and blueprint and the swagger annotation:\n\n```python\nfrom flasgger import swag_from\nfrom flask_restful import Resource, Api\n\ncontrol_blueprint = Blueprint(\"control\", __name__)\napi = Api(control_blueprint)\n\nclass SimulationController(Resource):\n    @swag_from('controlapi.yml')\n    def post(self):\n        # ..\napi.add_resource(SimulationController, \"/control\")\n```\n\nThe [Pipfile](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator/blob/master/Pipfile) defines the dependencies for this component, and is used by `pipenv` during the automatic build process within `appsody build`.\n\n\n**Github repository:** [vaccine-reefer-simulator](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator)\n\n**Kafka topics produced to:** telemetries\n\n**Event sents to the topic:**\n\n```python\n{\"containerID\": metric[0],\n\"timestamp\": str(metric[1]),\n\"type\":\"ReeferTelemetries\",\n\"payload\"={ \"timestamp\": \"2019-09-04 T15:31 Z\",\n            \"containerID\": \"C101\",\n            \"product_id\": \"P02\",\n            \"sensors\": {\n              \"temperature\": 2.49647,\n              \"oxygen_level\" : 20.4543,\n              \"nitrogen_level\" : 79.4046,\n              \"carbon_dioxide_level\" : 4.42579,\n              \"humidity_level\" : 60.3148,\n              \"fan_1\": \"True\",\n              \"fan_2\" : \"True\",\n              \"fan_3\" : \"True\",\n              \"ambiant_temperature\": 19.8447\n            },\n            \"content_type\": 1,\n            \"target_temperature\": 6.0,\n            \"kilowatts\": 3.44686,\n            \"latitude\": \"37.8226902168957,\",\n            \"longitude\": \"-122.3248956640928\",\n            \"time_door_open\" : 300,\n            \"defrost_cycle\": 6\n        }\n}\n```\n\n## Build\n\nThis microservice is built using the Appsody development framework. The Appsody CLI is a required prerequisite for building the application locally.\n\nAppsody will build the application by pulling the contents of the Appsody Stack it is based on and then performing the local application build inside the containerized environment:\n\n`appsody build -t ibmcase/vaccine-reefer-simulator:v1.0.0 --push`\n\nYou can optionally specify a container tag. If left blank, latest will be used.\nYou can optionally supply the --push flag to automatically push the built image to specified remote repository.\nPerforming an Appsody build will update the `app-deploy.yaml` file in the same directory with current information for the application image, labels, and annotations fields.\n\n## Run\n\nTo launch the web application in development mode, using a local kafka cluster based on Strimzi image 2.5, use the following commands:\n\n```shell\ndocker-compose up &\n# set environment variables - from simulator folder\nexport KAFKA_BROKERS=kafka:9092\n# Run the app with a local kafka broker started with docker compose\n$ appsody run --network kafkanet --docker-options=\"-e KAFKA_BROKERS=$KAFKA_BROKERS\"\n```\n\n### Run locally with remote Event Streams on OCP\n\nIf you want to remote connect to Event Streams on OpenShift, you need to get the external URL for the bootstrap end point and the TLS certificate in the form of a .pem file. The following commands can help you do so.\n\n```shell\n# login to OpenShift\noc login --token=L0.... --server=https://api.eda-solutions.gse-ocp.net:6443\n# Access to the project where event streams run\noc project integration\n# Access to Event Streams cluster\ncloudctl es init\n# From the result get the bootstrap address: some thing like:\n# ...-kafka-bootstrap-integration.apps.....:443 \n# Get the certificate\ncloudctl es certificates --format pem\nmv es-cert.pem certs/\n# Get one of the kafka user defined with the scram-sha-512 authentication\noc get kafkausers -n integration\n# For example here is an output: \n# NAME      AUTHENTICATION   AUTHORIZATION\n# my-user1  scram-sha-512    simple\n```\n\nSet the following environment variables:\n\n```shell\nexport KAFKA_BROKERS=...-kafka-bootstrap-integration.apps.....:443 \nexport KAFKA_USER=my-user1\nexport KAFKA_PWD=$(oc -n integration get secret my-user1 -o jsonpath='{.data.password}'  | base64 --decode)\n```\n\nThen start the app (the previous steps has to be done only for the first run):\n\n```shell\nappsody run --docker-options \"-e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_USER=$KAFKA_USER -e KAFKA_PWD=$KAFKA_PWD -v $(pwd)/certs/es-cert.pem:/certs\"\n```\n\nThe trace shows the Kafka configuration options:\n\n```shell\nKafka options are:\n[Container] {'bootstrap.servers': '....:443', 'group.id': 'ReeferTelemetryProducers', 'security.protocol': 'SASL_SSL', 'sasl.mechanisms': 'SRAM-SHA-512', 'sasl.username': 'my-user1', 'sasl.password': 'xC..VDc', 'ssl.ca.location': '/certs/es-cert.pem'}\n```\n\n\n### Testing\n\n#### Unit test the Simulator\n\nThe test coverage for this project is not great yet. To run the test use `appsody test`.\n\n```shell\ncd ./scripts\n./startPythonEnv.sh\nroot@1de81b16f940:/# export PYTHONPATH=/home/reeferiotsimulator\nroot@1de81b16f940:/# cd /home/reeferiotsimulator\nroot@1de81b16f940:/# python test/unit/TestSimulator.py\n```\n\n#### Functional testing\n\nTo be able to run locally, you need a Kafka simple cluster. We have defined a docker compose for that, see [previous section](#run).\n\nUse the web browser or a Postman to go to the URL: [http://localhost:8080/control](http://localhost:8080/control) and do a POST. Here is an image of the open API UI:\n\n![](images/simulapp-control-openapi.png)\n\n\n###  Deployment\n\n1. There are a set of required configuration elements for connectivity to IBM Event Streams (Kafka) prior to deploy this app:\n\n    * A `ConfigMap` named `reefer-simul-cmap`, that you deploy with `oc apply -f config/configmap.yaml`\n    * A user and user secret. If you have a defined a user in the Event Streams console name `kafka-user` with SRAM credentials, then we need to copy the secret in the name space where the service will run. For that do the following command: \n      ```\n      oc get secret kafka-user -n integration -o yaml | oc apply -f -\n      ```\n    * A `Secret` named `eventstreams-pem` for the pem file content.\n\n      ```\n      oc create secret generic eventstreams-pem --from-file=certs/es-cert.pem\n      ```\n\n1. Once those elements are defined it is important to configure the app so it can retrieve those information via environment variables. With Appsody the file `appsody-config.yaml` is supporting these configurations. \n\n  [See app-deploy.yaml](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator/blob/master/app-deploy.yaml)\n\n\n### Application deployment\n\nThe application can be deployed to a remote OpenShift cluster by using the `appsody deploy` command (We recommend reading [Appsody build and deploy product documentation](https://appsody.dev/docs/using-appsody/building-and-deploying/)):\n\n* Deploy using the docker image on public docker hub repository:\n\n```shell\n# login to the openshift cluster if not done already\noc login --token=rR.... --server=....\n# Deploy to the vaccine solution project\nappsody deploy -t ibmcase/vcc-reeferiotsimulator:v1.0.0 --push --namespace vaccine-solution\n```\n\nYou can verify the deployment with the CLI\n\n```shell\noc get pods -w\n```\n\nor the via the Openshift console:\n\n![](images/simul-app-ocp.png)\n\nAppsody has defined the service and expose the application via a route.\n\n```\noc get svc\noc describe route vaccine-reefer-simulator\n```\n\n* To delete the deployment: `appsody deploy delete`\n\n### Continuous deployment with Tekton\n\nThe general approach to use Tekton to deploy the components of the solution is defined in [this note](../devops/cd.md#tekton-appsody-deployments).\n\n## Demonstrate\n\nOnce deployed, you can access the Swagger-based REST API via the defined route and trigger the simulation controls.\n\n1. To determine the route, use the `oc get route reefer-simulator` command and go to the URL specified in the `HOST/PORT` field in your browser.\n2. From there, drill down into the `POST /control` section and click **Try it out!**.\n3. Enter any of the following options for the fields prepopulated in the `control` body: P01 is the covid-19 vaccine.\n\n    * Container: `C01, C02, C03, C04`\n    * Product: `P01, P02, P03, P04`\n    * Simulation: `poweroff, co2sensor, o2sensor, temperature, normal`\n    * Number of records: A positive integer\n\n4. Click **Execute**\n\n\n## More readings\n\n* [Flask Restful](https://flask-restful.readthedocs.io/en/latest/quickstart.html)\n* [Appsody build and deploy product documentation](https://appsody.dev/docs/using-appsody/building-and-deploying/)\n","type":"Mdx","contentDigest":"2fae0970e297fac8c07a439b52532e34","counter":255,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"The Reefer Simulator as web app","description":"Simple Refrigerator container internet of thing simulator to control temperature, co2, o2 or power sensors to help build dataset or run time monitoring solution."},"exports":{},"rawBody":"---\ntitle: The Reefer Simulator as web app\ndescription: Simple Refrigerator container internet of thing simulator to control temperature, co2, o2 or power sensors to help build dataset or run time monitoring solution.\n---\n\n\n<PageDescription>\nThis Simulator web application is a simple python (3.7) Flask app exposing a REST POST end point to control the type of simulation we want to run and to produce refrigerator container telemetry events to kafka `telemetries` topic.\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Build</AnchorLink>\n  <AnchorLink>Run</AnchorLink>\n  <AnchorLink>Usage Details</AnchorLink>\n</AnchorLinks>\n\n## Overview\n\n\n### Application requirements\n\nThe simulator is not in the critical path for production like component. It is here to help us develop the other components of the solution as we do not have real life Refrigerator container. Here are the simple user stories for this app:\n\n1. when I want to generate mockup telemetries data for my data scientist friend, I want to start the simulator tool from command line so I can get a csv file with telemetry data\n1. when I want to generate mockup telemetries data for my data scientist friend, I want to be able to simulate co2 sensor, o2 sensor, temperature and power sensor issue so I can get relevant data for the machine learning model to make sense\n1. when I want to generate mockup telemetries data for my data scientist friend, I want to start the simulator tool from command line using parameter so I can get save data to a remote document oriented database: mongodb on IBM cloud.\n1. when I want to demonstrate the solution, I want to call a REST api to control the generation of faulty sensor data so I can get the scoring service returning maintenance needed.\n1. when I want to demonstrate the cold chain violation, I want to call a REST api to control a change to the temperature over a time period so cold chain violation can be identified with a complex event processing or AI model.\n\n ![1](./images/reefer-simul-1.png)\n\nThe simulator needs to integrate with kafka / IBM Event Streams deployed as service on the cloud or deployed on OpenShift cluster using Cloud Pak for Integration.\n\n### Design approach\n\nTo support remote control of the simulator while running as webapp, we define a POST operation on the `/control` URL:\n\n![1](images/simulapp-control-swagger.png)\n\n The Json control object defines the number records to produce, the sensor to impact (co2sensor, temperature, o2sensor, power) , the container ID, (one of C01, C02, C03, C04) which carries the product referenced by product_id (one of P01, P02, P03, P04, P05) - The P01 is the covid-19 vaccine:\n\n```json\n    { 'containerID': 'C02',\n    'simulation': 'temperature',\n    'nb_of_records': 4000,\n    \"product_id\":  \"P01\"\n    }\n```\n\nWe have tried to support a domain driven design approach to structure the code, with domain, infrastructure and app modules. The domain module has a unique class for the simulator which main goal is to generate data tuples or records for the different simulation types. It is reused by the standalone simulation CLI tool to generate data at rest, if needed.\n\nAs the simulator is also a webapp we need to package it with [Flask](https://www.fullstackpython.com/flask.html) and run it using one of the Web Server Gateway Interface (WSGI) implementation, like [Gunicorn](http://docs.gunicorn.org/).\n\nIf you want to go over the code, ee recommend to follow [Flask tutorial](https://flask.palletsprojects.com/en/1.1.x/tutorial/).\n\nFlask is a simple library to implement REST based microservice and web application in Python. It has other related projects to add interesting features to develop production ready application. The standard development includes defining routes, function to support handling the request and generating HTTP response, but also defining APIs... Read more with the [explore Flask book online](http://exploreflask.com/en/latest/).\n\nFlask is mono threaded so it fits well in a simple web application for development purpose, but for production it is recommended to add a web server like [Gunicorn](https://gunicorn.org/) to handle multiple concurrent requests.\n\n### Anatomy\n\nThe application is built using [Appsody](https://appsody.dev). The [Appsody CLI](https://appsody.dev/docs/getting-started/installation) is required locally to build and deploy the application properly.\n\nThe app is done using Flask, and the code is generated using `appsody init python-flask` command with the Python Flask appsody stack and template.\n\nWe recommend reading [the Python Flask Appsody Stack git hub repo](https://github.com/appsody/stacks/tree/master/incubator/python-flask) to get familiar with the appsody python stack.\n\nThe Flask application imports the 'userapp' where the real application code resides, and adds blueprints to define health and metrics APIs:\n\n```python\nfrom flask import Flask\n\napp = Flask(__name__)\n\nfrom userapp import *\n\nfrom server.routes.health import health_bp\napp.register_blueprint(health_bp)\nfrom server.routes.prometheus import metrics_bp\napp.register_blueprint(metrics_bp)\n```\n\nThis code is not updateable, as it is part of the appsody stack image. But we can add our business logic as part of the `domain/__init__.py` code using another [Flask blueprints](https://flask.palletsprojects.com/en/1.1.x/blueprints/) module [api/controller.py]().\n\nThe `userapp` module is defined when appsody integrates our code with the base stack image using Docker. Below is an extract of the docker file managing module installation and defining what appsody does during build, run and test:\n\n```dockerfile\nENV APPSODY_MOUNTS=/:/project/userapp\nENV APPSODY_DEPS=/project/deps\nWORKDIR /project\nRUN python -m pip install -r requirements.txt -t /project/deps\nENV FLASK_APP=server/__init__.py\n```\n\nLooking at the content of the final docker container running the application we can see this structure:\n\n```\n/project\n|-- Dockerfile\n    Pipfile\n    Pipfile.lock\n    constraints.txt\n    requirements.txt\n    deps/\n    server/\n    test/\n    userapp/\n```\n\nThe basic concept of blueprints is that they record operations to execute when each operation is registered on an application. So to add one operation to support a new control, we add a blueprint, and then register it in the main application: `__init__py`.\n\n```python\nfrom userapp.api.controller import control_blueprint\napp.register_blueprint(control_blueprint)\n```\n\nTo define the API, we use [Flasgger](https://github.com/flasgger/flasgger) as an extension to Flask to extract [Open API specification](https://swagger.io/docs/specification/about/) from the code. It comes with Swagger UI, so we can see the API documentation of the microservice at the URL `/apidocs`.  It can also validate the data according to the schema defined.\n\nFor the POST `/control` we defined the Swagger 2.0 API in a separate file: `api/controlapi.yml` and import it at the method level to support the POST operation. This method is defined in its blueprint as a REST resource. The code [controller.py](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator/blob/master/simulator/api/controller.py) is under `api` folder.\n\nBelow is a code extract to illustrate the use of Flask-RESTful and blueprint and the swagger annotation:\n\n```python\nfrom flasgger import swag_from\nfrom flask_restful import Resource, Api\n\ncontrol_blueprint = Blueprint(\"control\", __name__)\napi = Api(control_blueprint)\n\nclass SimulationController(Resource):\n    @swag_from('controlapi.yml')\n    def post(self):\n        # ..\napi.add_resource(SimulationController, \"/control\")\n```\n\nThe [Pipfile](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator/blob/master/Pipfile) defines the dependencies for this component, and is used by `pipenv` during the automatic build process within `appsody build`.\n\n\n**Github repository:** [vaccine-reefer-simulator](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator)\n\n**Kafka topics produced to:** telemetries\n\n**Event sents to the topic:**\n\n```python\n{\"containerID\": metric[0],\n\"timestamp\": str(metric[1]),\n\"type\":\"ReeferTelemetries\",\n\"payload\"={ \"timestamp\": \"2019-09-04 T15:31 Z\",\n            \"containerID\": \"C101\",\n            \"product_id\": \"P02\",\n            \"sensors\": {\n              \"temperature\": 2.49647,\n              \"oxygen_level\" : 20.4543,\n              \"nitrogen_level\" : 79.4046,\n              \"carbon_dioxide_level\" : 4.42579,\n              \"humidity_level\" : 60.3148,\n              \"fan_1\": \"True\",\n              \"fan_2\" : \"True\",\n              \"fan_3\" : \"True\",\n              \"ambiant_temperature\": 19.8447\n            },\n            \"content_type\": 1,\n            \"target_temperature\": 6.0,\n            \"kilowatts\": 3.44686,\n            \"latitude\": \"37.8226902168957,\",\n            \"longitude\": \"-122.3248956640928\",\n            \"time_door_open\" : 300,\n            \"defrost_cycle\": 6\n        }\n}\n```\n\n## Build\n\nThis microservice is built using the Appsody development framework. The Appsody CLI is a required prerequisite for building the application locally.\n\nAppsody will build the application by pulling the contents of the Appsody Stack it is based on and then performing the local application build inside the containerized environment:\n\n`appsody build -t ibmcase/vaccine-reefer-simulator:v1.0.0 --push`\n\nYou can optionally specify a container tag. If left blank, latest will be used.\nYou can optionally supply the --push flag to automatically push the built image to specified remote repository.\nPerforming an Appsody build will update the `app-deploy.yaml` file in the same directory with current information for the application image, labels, and annotations fields.\n\n## Run\n\nTo launch the web application in development mode, using a local kafka cluster based on Strimzi image 2.5, use the following commands:\n\n```shell\ndocker-compose up &\n# set environment variables - from simulator folder\nexport KAFKA_BROKERS=kafka:9092\n# Run the app with a local kafka broker started with docker compose\n$ appsody run --network kafkanet --docker-options=\"-e KAFKA_BROKERS=$KAFKA_BROKERS\"\n```\n\n### Run locally with remote Event Streams on OCP\n\nIf you want to remote connect to Event Streams on OpenShift, you need to get the external URL for the bootstrap end point and the TLS certificate in the form of a .pem file. The following commands can help you do so.\n\n```shell\n# login to OpenShift\noc login --token=L0.... --server=https://api.eda-solutions.gse-ocp.net:6443\n# Access to the project where event streams run\noc project integration\n# Access to Event Streams cluster\ncloudctl es init\n# From the result get the bootstrap address: some thing like:\n# ...-kafka-bootstrap-integration.apps.....:443 \n# Get the certificate\ncloudctl es certificates --format pem\nmv es-cert.pem certs/\n# Get one of the kafka user defined with the scram-sha-512 authentication\noc get kafkausers -n integration\n# For example here is an output: \n# NAME      AUTHENTICATION   AUTHORIZATION\n# my-user1  scram-sha-512    simple\n```\n\nSet the following environment variables:\n\n```shell\nexport KAFKA_BROKERS=...-kafka-bootstrap-integration.apps.....:443 \nexport KAFKA_USER=my-user1\nexport KAFKA_PWD=$(oc -n integration get secret my-user1 -o jsonpath='{.data.password}'  | base64 --decode)\n```\n\nThen start the app (the previous steps has to be done only for the first run):\n\n```shell\nappsody run --docker-options \"-e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_USER=$KAFKA_USER -e KAFKA_PWD=$KAFKA_PWD -v $(pwd)/certs/es-cert.pem:/certs\"\n```\n\nThe trace shows the Kafka configuration options:\n\n```shell\nKafka options are:\n[Container] {'bootstrap.servers': '....:443', 'group.id': 'ReeferTelemetryProducers', 'security.protocol': 'SASL_SSL', 'sasl.mechanisms': 'SRAM-SHA-512', 'sasl.username': 'my-user1', 'sasl.password': 'xC..VDc', 'ssl.ca.location': '/certs/es-cert.pem'}\n```\n\n\n### Testing\n\n#### Unit test the Simulator\n\nThe test coverage for this project is not great yet. To run the test use `appsody test`.\n\n```shell\ncd ./scripts\n./startPythonEnv.sh\nroot@1de81b16f940:/# export PYTHONPATH=/home/reeferiotsimulator\nroot@1de81b16f940:/# cd /home/reeferiotsimulator\nroot@1de81b16f940:/# python test/unit/TestSimulator.py\n```\n\n#### Functional testing\n\nTo be able to run locally, you need a Kafka simple cluster. We have defined a docker compose for that, see [previous section](#run).\n\nUse the web browser or a Postman to go to the URL: [http://localhost:8080/control](http://localhost:8080/control) and do a POST. Here is an image of the open API UI:\n\n![](images/simulapp-control-openapi.png)\n\n\n###  Deployment\n\n1. There are a set of required configuration elements for connectivity to IBM Event Streams (Kafka) prior to deploy this app:\n\n    * A `ConfigMap` named `reefer-simul-cmap`, that you deploy with `oc apply -f config/configmap.yaml`\n    * A user and user secret. If you have a defined a user in the Event Streams console name `kafka-user` with SRAM credentials, then we need to copy the secret in the name space where the service will run. For that do the following command: \n      ```\n      oc get secret kafka-user -n integration -o yaml | oc apply -f -\n      ```\n    * A `Secret` named `eventstreams-pem` for the pem file content.\n\n      ```\n      oc create secret generic eventstreams-pem --from-file=certs/es-cert.pem\n      ```\n\n1. Once those elements are defined it is important to configure the app so it can retrieve those information via environment variables. With Appsody the file `appsody-config.yaml` is supporting these configurations. \n\n  [See app-deploy.yaml](https://github.com/ibm-cloud-architecture/vaccine-reefer-simulator/blob/master/app-deploy.yaml)\n\n\n### Application deployment\n\nThe application can be deployed to a remote OpenShift cluster by using the `appsody deploy` command (We recommend reading [Appsody build and deploy product documentation](https://appsody.dev/docs/using-appsody/building-and-deploying/)):\n\n* Deploy using the docker image on public docker hub repository:\n\n```shell\n# login to the openshift cluster if not done already\noc login --token=rR.... --server=....\n# Deploy to the vaccine solution project\nappsody deploy -t ibmcase/vcc-reeferiotsimulator:v1.0.0 --push --namespace vaccine-solution\n```\n\nYou can verify the deployment with the CLI\n\n```shell\noc get pods -w\n```\n\nor the via the Openshift console:\n\n![](images/simul-app-ocp.png)\n\nAppsody has defined the service and expose the application via a route.\n\n```\noc get svc\noc describe route vaccine-reefer-simulator\n```\n\n* To delete the deployment: `appsody deploy delete`\n\n### Continuous deployment with Tekton\n\nThe general approach to use Tekton to deploy the components of the solution is defined in [this note](../devops/cd.md#tekton-appsody-deployments).\n\n## Demonstrate\n\nOnce deployed, you can access the Swagger-based REST API via the defined route and trigger the simulation controls.\n\n1. To determine the route, use the `oc get route reefer-simulator` command and go to the URL specified in the `HOST/PORT` field in your browser.\n2. From there, drill down into the `POST /control` section and click **Try it out!**.\n3. Enter any of the following options for the fields prepopulated in the `control` body: P01 is the covid-19 vaccine.\n\n    * Container: `C01, C02, C03, C04`\n    * Product: `P01, P02, P03, P04`\n    * Simulation: `poweroff, co2sensor, o2sensor, temperature, normal`\n    * Number of records: A positive integer\n\n4. Click **Execute**\n\n\n## More readings\n\n* [Flask Restful](https://flask-restful.readthedocs.io/en/latest/quickstart.html)\n* [Appsody build and deploy product documentation](https://appsody.dev/docs/using-appsody/building-and-deploying/)\n","fileAbsolutePath":"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/src/pages/solution/reefer-iot/index.mdx"}}}}